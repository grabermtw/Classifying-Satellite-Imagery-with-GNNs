{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Satellite Imagery with GNNs\n",
    "## CIS700\n",
    "\n",
    "### Matt Graber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the data\n",
    "\n",
    "First, we will obtain the data. We will be attempting to classify the Corrected Reflectance (True Color) Suomi NPP / VIIRS product available from the Global Imagery Browse Services (GIBS) API. To label the data for training and testing, we will be using the Clear Sky Confidence (Day) Suomi NPP / VIRRS product and the Land Water Map (OSM) (from Open Street Map served through GIBS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrected Reflectance (True Color) Layer example: https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?version=1.3.0&service=WMS&request=GetMap&format=image/png&STYLE=default&bbox=-90,-180,90,180CRS=EPSG:4326&HEIGHT=600&WIDTH=600&TIME=2022-05-01&layers=VIIRS_SNPP_CorrectedReflectance_TrueColor\n",
    "\n",
    "Clear Sky Confidence Layer Example: https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?version=1.3.0&service=WMS&request=GetMap&format=image/png&STYLE=default&bbox=-90,-180,90,180CRS=EPSG:4326&HEIGHT=600&WIDTH=600&TIME=2022-05-01&layers=VIIRS_SNPP_Clear_Sky_Confidence_Day\n",
    "\n",
    "Land Water Map Layer Example: https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?version=1.3.0&service=WMS&request=GetMap&format=image/png&STYLE=default&bbox=-90,-180,90,180CRS=EPSG:4326&HEIGHT=600&WIDTH=600&TIME=2022-05-01&layers=OSM_Land_Water_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image as plimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VIIRS_SNPP_CorrectedReflectance_TrueColor images...\n",
      "Downloading images for 2022-05-01...\n",
      "Downloading images for 2022-05-02...\n",
      "Downloading images for 2022-05-03...\n",
      "Downloading VIIRS_SNPP_Clear_Sky_Confidence_Day images...\n",
      "Downloading images for 2022-05-01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: IDAT: CRC error\n",
      "libpng error: bad adaptive filter value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images for 2022-05-02...\n",
      "Downloading images for 2022-05-03...\n",
      "Downloading OSM_Land_Water_Map images...\n"
     ]
    }
   ],
   "source": [
    "layers = [\"VIIRS_SNPP_CorrectedReflectance_TrueColor\", \"VIIRS_SNPP_Clear_Sky_Confidence_Day\"]\n",
    "startdate = datetime.date(2022,5,1)\n",
    "enddate = datetime.date(2022,5,4)\n",
    "img_extent_step = 5\n",
    "resolution = 128\n",
    "\n",
    "for layer in layers:\n",
    "    print(\"Downloading {} images...\".format(layer))\n",
    "    layer_outdir = os.path.join(os.getcwd(), \"images\", layer)\n",
    "    currentdate = startdate\n",
    "\n",
    "    while currentdate < enddate:\n",
    "        outdir = os.path.join(layer_outdir, str(currentdate))\n",
    "        \n",
    "         # Create directory if it doesn't exist yet\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir, exist_ok=True)\n",
    "            \n",
    "        print(\"Downloading images for {}...\".format(currentdate))\n",
    "        for longitude in range(-180,180,img_extent_step):\n",
    "            for latitude in range(-90,90,img_extent_step):\n",
    "                extents = \"{0},{1},{2},{3}\".format(latitude, longitude,\n",
    "                                                latitude + img_extent_step,\n",
    "                                                longitude + img_extent_step)\n",
    "                outfilepath = os.path.join(outdir,'{0}_{1}_{2}.png'.format(layer, currentdate, extents))\n",
    "                # Skip any files that have already been downloaded\n",
    "                # (this enables quick resumption if connection errors are encountered).\n",
    "                # put this in a while-loop in case there's a connection error and\n",
    "                # the download for something needs to be retried\n",
    "                while not os.path.exists(outfilepath) or cv2.imread(outfilepath) is None:\n",
    "                    # Construct image URL.\n",
    "                    url = 'https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?\\\n",
    "version=1.3.0&service=WMS&request=GetMap&\\\n",
    "format=image/png&STYLE=default&bbox={0}&CRS=EPSG:4326&\\\n",
    "HEIGHT={3}&WIDTH={3}&TIME={1}&layers={2}'.format(extents, currentdate, layer, resolution)\n",
    "                    \n",
    "                    # Occasionally we get an error from a momentary dropout of internet connection or something.\n",
    "                    # This try-except should \n",
    "                    try:\n",
    "                        # Request and save image\n",
    "                        img = plimg.fromarray(io.imread(url))\n",
    "                        img.save(outfilepath)\n",
    "                    except:\n",
    "                        print(\"Error encountered, retrying\")\n",
    "                        time.sleep(5)\n",
    "\n",
    "        currentdate += datetime.timedelta(1)\n",
    "\n",
    "# OSM_Land_Water_Map is a static layer, meaning that we don't need to re-download it for every day.\n",
    "layer = \"OSM_Land_Water_Map\"\n",
    "print(\"Downloading {} images...\".format(layer))\n",
    "outdir = os.path.join(os.getcwd(), \"images\", \"{}\".format(layer))\n",
    "\n",
    "# Create directory if it doesn't exist yet\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "for longitude in range(-180,180,img_extent_step):\n",
    "    for latitude in range(-90,90,img_extent_step):\n",
    "        extents = \"{0},{1},{2},{3}\".format(latitude, longitude,\n",
    "                                        latitude + img_extent_step,\n",
    "                                        longitude + img_extent_step)\n",
    "        outfilepath = os.path.join(outdir,'{0}_{1}.png'.format(layer, extents))\n",
    "        # Skip any files that have already been downloaded\n",
    "        # (this enables quick resumption if connection errors are encountered)\n",
    "        while not os.path.exists(outfilepath) or cv2.imread(outfilepath) is None:\n",
    "            # Construct image URL.\n",
    "            url = 'https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?\\\n",
    "version=1.3.0&service=WMS&request=GetMap&\\\n",
    "format=image/png&STYLE=default&bbox={0}&CRS=EPSG:4326&\\\n",
    "HEIGHT={2}&WIDTH={2}&layers={1}'.format(extents, layer, resolution)\n",
    "            # Occasionally we get an error from a momentary dropout of internet connection or something.\n",
    "            # This try-except should \n",
    "            try:\n",
    "                # Request and save image\n",
    "                img = plimg.fromarray(io.imread(url))\n",
    "                img.save(outfilepath)\n",
    "            except:\n",
    "                print(\"Error encountered, retrying\")\n",
    "                time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling the data\n",
    "Next, we will label each Corrected Reflectance image to indicate whether it contains land, water, and/or clouds to use as the training data for the neural networks. We will do this based on the percentages of colors in the corresponding images from Clear Sky Confidence and Land Water Map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling for date 2022-05-01...\n",
      "Labeling for date 2022-05-02...\n",
      "Labeling for date 2022-05-03...\n",
      "Labeling complete!\n"
     ]
    }
   ],
   "source": [
    "labeled_data_filename = \"labeled_data.csv\"\n",
    "\n",
    "layer_to_label_path = os.path.join(\"images\",\"VIIRS_SNPP_CorrectedReflectance_TrueColor\")\n",
    "clear_sky_layer_path = os.path.join(\"images\", \"VIIRS_SNPP_Clear_Sky_Confidence_Day\")\n",
    "land_water_map_path = os.path.join(\"images\", \"OSM_Land_Water_Map\")\n",
    "lw_filelist = os.listdir(land_water_map_path)\n",
    "\n",
    "resolution = 128\n",
    "pixel_count = resolution ** 2\n",
    "# Exclude any images where 40% or more of the image is \"no data\"\n",
    "nodata_threshold = pixel_count * 0.6\n",
    "\n",
    "# dict for memoization of land water map results, since this is a static layer\n",
    "lw_results = {}\n",
    "\n",
    "with open(labeled_data_filename, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filepath\", \"weather\", \"terrain\"])\n",
    "    for date in os.listdir(layer_to_label_path):\n",
    "        print(\"Labeling for date {}...\".format(date))\n",
    "        co_re_datepath = os.path.join(layer_to_label_path, date)\n",
    "        cl_sk_datepath = os.path.join(clear_sky_layer_path, date)\n",
    "        co_re_filelist = os.listdir(co_re_datepath)\n",
    "        cl_sk_filelist = os.listdir(cl_sk_datepath)\n",
    "        for i in range(len(co_re_filelist)):\n",
    "            # these directories should be ordered the same\n",
    "            co_re_imgpath = os.path.join(co_re_datepath, co_re_filelist[i])\n",
    "            cl_sk_imgpath = os.path.join(cl_sk_datepath, cl_sk_filelist[i])\n",
    "            \n",
    "            csv_row = [co_re_imgpath]\n",
    "\n",
    "            # First, check if the corrected reflectance image is in an area of \"no data\"\n",
    "            # i.e. it's all or mostly pure black.\n",
    "            # We want to skip these images.\n",
    "            co_re_img = cv2.imread(co_re_imgpath, 0) # use 0 flag to read grayscale\n",
    "            if cv2.countNonZero(co_re_img) < nodata_threshold:\n",
    "                continue\n",
    "\n",
    "            # Next, check if the image is mostly cloudy or not cloudy.\n",
    "            # In this layer, the reddish color (the higher pixel value) corresponds to clear skies,\n",
    "            # and the whiteish color (the lower pixel value) corresponds to cloudy skies.\n",
    "            cl_sk_img = cv2.imread(cl_sk_imgpath, 0)\n",
    "            \n",
    "            # If there are more dark-colored pixels than light-colored pixels, then it's not cloudy.\n",
    "            if cv2.countNonZero(cv2.inRange(cl_sk_img, 0, 127)) > cv2.countNonZero(cv2.inRange(cl_sk_img, 128, 255)):\n",
    "                # clear skies\n",
    "                csv_row.append(\"clear\")\n",
    "            else:\n",
    "                # cloudy skies\n",
    "                csv_row.append(\"cloudy\")\n",
    "\n",
    "            # Finally, check if the image is mostly land or water.\n",
    "            lw_imgpath = os.path.join(land_water_map_path, lw_filelist[i])\n",
    "            if lw_imgpath in lw_results.keys():\n",
    "                csv_row.append(lw_results[lw_imgpath])\n",
    "            else:\n",
    "                lw_img = cv2.imread(lw_imgpath, 0)\n",
    "                # If there are more light-colored pixels than dark-colored pixels, then its mostly water\n",
    "                if cv2.countNonZero(cv2.inRange(lw_img, 128, 128)) > cv2.countNonZero(cv2.inRange(lw_img, 75, 75)):\n",
    "                    lw_results[lw_imgpath] = \"water\"\n",
    "                else:\n",
    "                    lw_results[lw_imgpath] = \"land\"\n",
    "                csv_row.append(lw_results[lw_imgpath])\n",
    "            writer.writerow(csv_row)\n",
    "\n",
    "print(\"Labeling complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (non-graph)\n",
    "Now that our data is labeled, we can start by training a baseline non-graph convolutional neural network classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2221/1930965448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# convert from strings to int representation of the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sknn/mlp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mansi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sknn.mlp import Classifier, Convolution, Layer\n",
    "\n",
    "# convert from strings to int representation of the labels\n",
    "def encode(label):\n",
    "    if label in ['clear', 'water']:\n",
    "        return 0\n",
    "    else: # cloudy, land\n",
    "        return 1\n",
    "\n",
    "# Used for obtaining the training/testing data\n",
    "def load_data(filename):\n",
    "    imgs = []\n",
    "    weather = []\n",
    "    terrain = []\n",
    "    with open(filename) as datacsv:\n",
    "        reader = csv.DictReader(datacsv)\n",
    "        for row in reader:\n",
    "            imgs.append(row[\"filepath\"])\n",
    "            weather.append(row[\"weather\"])\n",
    "            terrain.append(row[\"terrain\"])\n",
    "    shufflelist = list(zip(imgs, weather, terrain))\n",
    "    random.shuffle(shufflelist)\n",
    "    imgs, weather, terrain = zip(*shufflelist)\n",
    "    imgs, weather, terrain = list(imgs), list(weather), list(terrain)\n",
    "    # split into training and test data (use 3/4 for training, 1/4 for testing)\n",
    "    split_size = int(0.75 * len(imgs))\n",
    "    training_data = (imgs[:split_size], weather[:split_size], terrain[:split_size])\n",
    "    testing_data = (imgs[split_size:], weather[split_size:], terrain[split_size:])\n",
    "    return training_data, testing_data\n",
    "\n",
    "filename = \"labeled_data.csv\"\n",
    "training_data, testing_data = load_data(filename)\n",
    "train_imgs, train_weather, train_terrain = training_data\n",
    "\n",
    "X_train = train_imgs\n",
    "for y_train in [train_weather, train_terrain]:\n",
    "    nn = Classifier(\n",
    "        layers=[\n",
    "            Convolution(\"Rectifier\", channels=8, kernel_shape=(3,3)),\n",
    "            Layer(\"Softmax\")],\n",
    "        learning_rate=0.02,\n",
    "        n_iter=5)\n",
    "    nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc2b5acaa58da8cb98f2f1f9c5a12e7ec9d328c197ca9485c680430a79d86e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
