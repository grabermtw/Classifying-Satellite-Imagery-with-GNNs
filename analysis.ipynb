{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Satellite Imagery with GNNs\n",
    "## CIS700\n",
    "\n",
    "### Matt Graber"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the data\n",
    "\n",
    "First, we will obtain the data. We will be attempting to classify the Corrected Reflectance (True Color) Suomi NPP / VIIRS product available from the Global Imagery Browse Services (GIBS) API. To label the data for training and testing, we will be using the Clear Sky Confidence (Day) Suomi NPP / VIRRS product and the Land Water Map (OSM) (from Open Street Map served through GIBS)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrected Reflectance (True Color) Layer example: https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?version=1.3.0&service=WMS&request=GetMap&format=image/png&STYLE=default&bbox=-90,-180,90,180CRS=EPSG:4326&HEIGHT=600&WIDTH=600&TIME=2022-05-01&layers=VIIRS_SNPP_CorrectedReflectance_TrueColor\n",
    "\n",
    "Clear Sky Confidence Layer Example: https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?version=1.3.0&service=WMS&request=GetMap&format=image/png&STYLE=default&bbox=-90,-180,90,180CRS=EPSG:4326&HEIGHT=600&WIDTH=600&TIME=2022-05-01&layers=VIIRS_SNPP_Clear_Sky_Confidence_Day\n",
    "\n",
    "Land Water Map Layer Example: https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?version=1.3.0&service=WMS&request=GetMap&format=image/png&STYLE=default&bbox=-90,-180,90,180CRS=EPSG:4326&HEIGHT=600&WIDTH=600&TIME=2022-05-01&layers=OSM_Land_Water_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image as plimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VIIRS_SNPP_CorrectedReflectance_TrueColor images...\n",
      "Downloading images for 2022-05-01...\n",
      "Downloading images for 2022-05-02...\n",
      "Downloading images for 2022-05-03...\n",
      "Downloading VIIRS_SNPP_Clear_Sky_Confidence_Day images...\n",
      "Downloading images for 2022-05-01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: IDAT: CRC error\n",
      "libpng error: bad adaptive filter value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images for 2022-05-02...\n",
      "Downloading images for 2022-05-03...\n",
      "Downloading OSM_Land_Water_Map images...\n"
     ]
    }
   ],
   "source": [
    "layers = [\"VIIRS_SNPP_CorrectedReflectance_TrueColor\", \"VIIRS_SNPP_Clear_Sky_Confidence_Day\"]\n",
    "startdate = datetime.date(2022,5,1)\n",
    "enddate = datetime.date(2022,5,4)\n",
    "img_extent_step = 5\n",
    "resolution = 128\n",
    "\n",
    "for layer in layers:\n",
    "    print(\"Downloading {} images...\".format(layer))\n",
    "    layer_outdir = os.path.join(os.getcwd(), \"images\", layer)\n",
    "    currentdate = startdate\n",
    "\n",
    "    while currentdate < enddate:\n",
    "        outdir = os.path.join(layer_outdir, str(currentdate))\n",
    "        \n",
    "         # Create directory if it doesn't exist yet\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir, exist_ok=True)\n",
    "            \n",
    "        print(\"Downloading images for {}...\".format(currentdate))\n",
    "        for longitude in range(-180,180,img_extent_step):\n",
    "            for latitude in range(-90,90,img_extent_step):\n",
    "                extents = \"{0},{1},{2},{3}\".format(latitude, longitude,\n",
    "                                                latitude + img_extent_step,\n",
    "                                                longitude + img_extent_step)\n",
    "                outfilepath = os.path.join(outdir,'{0}_{1}_{2}.png'.format(layer, currentdate, extents))\n",
    "                # Skip any files that have already been downloaded\n",
    "                # (this enables quick resumption if connection errors are encountered).\n",
    "                # put this in a while-loop in case there's a connection error and\n",
    "                # the download for something needs to be retried\n",
    "                while not os.path.exists(outfilepath) or cv2.imread(outfilepath) is None:\n",
    "                    # Construct image URL.\n",
    "                    url = 'https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?\\\n",
    "version=1.3.0&service=WMS&request=GetMap&\\\n",
    "format=image/png&STYLE=default&bbox={0}&CRS=EPSG:4326&\\\n",
    "HEIGHT={3}&WIDTH={3}&TIME={1}&layers={2}'.format(extents, currentdate, layer, resolution)\n",
    "                    \n",
    "                    # Occasionally we get an error from a momentary dropout of internet connection or something.\n",
    "                    # This try-except should \n",
    "                    try:\n",
    "                        # Request and save image\n",
    "                        img = plimg.fromarray(io.imread(url))\n",
    "                        img.save(outfilepath)\n",
    "                    except:\n",
    "                        print(\"Error encountered, retrying\")\n",
    "                        time.sleep(5)\n",
    "\n",
    "        currentdate += datetime.timedelta(1)\n",
    "\n",
    "# OSM_Land_Water_Map is a static layer, meaning that we don't need to re-download it for every day.\n",
    "layer = \"OSM_Land_Water_Map\"\n",
    "print(\"Downloading {} images...\".format(layer))\n",
    "outdir = os.path.join(os.getcwd(), \"images\", \"{}\".format(layer))\n",
    "\n",
    "# Create directory if it doesn't exist yet\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "for longitude in range(-180,180,img_extent_step):\n",
    "    for latitude in range(-90,90,img_extent_step):\n",
    "        extents = \"{0},{1},{2},{3}\".format(latitude, longitude,\n",
    "                                        latitude + img_extent_step,\n",
    "                                        longitude + img_extent_step)\n",
    "        outfilepath = os.path.join(outdir,'{0}_{1}.png'.format(layer, extents))\n",
    "        # Skip any files that have already been downloaded\n",
    "        # (this enables quick resumption if connection errors are encountered)\n",
    "        while not os.path.exists(outfilepath) or cv2.imread(outfilepath) is None:\n",
    "            # Construct image URL.\n",
    "            url = 'https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi?\\\n",
    "version=1.3.0&service=WMS&request=GetMap&\\\n",
    "format=image/png&STYLE=default&bbox={0}&CRS=EPSG:4326&\\\n",
    "HEIGHT={2}&WIDTH={2}&layers={1}'.format(extents, layer, resolution)\n",
    "            # Occasionally we get an error from a momentary dropout of internet connection or something.\n",
    "            # This try-except should \n",
    "            try:\n",
    "                # Request and save image\n",
    "                img = plimg.fromarray(io.imread(url))\n",
    "                img.save(outfilepath)\n",
    "            except:\n",
    "                print(\"Error encountered, retrying\")\n",
    "                time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling the data\n",
    "Next, we will label each Corrected Reflectance image to indicate whether it contains land, water, and/or clouds to use as the training data for the neural networks. We will do this based on the percentages of colors in the corresponding images from Clear Sky Confidence and Land Water Map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling for date 2022-05-01...\n",
      "Labeling for date 2022-05-02...\n",
      "Labeling for date 2022-05-03...\n",
      "Labeling complete!\n"
     ]
    }
   ],
   "source": [
    "labeled_data_filename = \"labeled_data.csv\"\n",
    "\n",
    "layer_to_label_path = os.path.join(\"images\",\"VIIRS_SNPP_CorrectedReflectance_TrueColor\")\n",
    "clear_sky_layer_path = os.path.join(\"images\", \"VIIRS_SNPP_Clear_Sky_Confidence_Day\")\n",
    "land_water_map_path = os.path.join(\"images\", \"OSM_Land_Water_Map\")\n",
    "lw_filelist = os.listdir(land_water_map_path)\n",
    "\n",
    "resolution = 128\n",
    "pixel_count = resolution ** 2\n",
    "# Exclude any images where 40% or more of the image is \"no data\"\n",
    "nodata_threshold = pixel_count * 0.6\n",
    "\n",
    "# dict for memoization of land water map results, since this is a static layer\n",
    "lw_results = {}\n",
    "\n",
    "with open(labeled_data_filename, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filepath\", \"weather\", \"terrain\"])\n",
    "    for date in os.listdir(layer_to_label_path):\n",
    "        print(\"Labeling for date {}...\".format(date))\n",
    "        co_re_datepath = os.path.join(layer_to_label_path, date)\n",
    "        cl_sk_datepath = os.path.join(clear_sky_layer_path, date)\n",
    "        co_re_filelist = os.listdir(co_re_datepath)\n",
    "        cl_sk_filelist = os.listdir(cl_sk_datepath)\n",
    "        for i in range(len(co_re_filelist)):\n",
    "            # these directories should be ordered the same\n",
    "            co_re_imgpath = os.path.join(co_re_datepath, co_re_filelist[i])\n",
    "            cl_sk_imgpath = os.path.join(cl_sk_datepath, cl_sk_filelist[i])\n",
    "            \n",
    "            csv_row = [co_re_imgpath]\n",
    "\n",
    "            # First, check if the corrected reflectance image is in an area of \"no data\"\n",
    "            # i.e. it's all or mostly pure black.\n",
    "            # We want to skip these images.\n",
    "            co_re_img = cv2.imread(co_re_imgpath, 0) # use 0 flag to read grayscale\n",
    "            if cv2.countNonZero(co_re_img) < nodata_threshold:\n",
    "                continue\n",
    "\n",
    "            # Next, check if the image is mostly cloudy or not cloudy.\n",
    "            # In this layer, the reddish color (the higher pixel value) corresponds to clear skies,\n",
    "            # and the whiteish color (the lower pixel value) corresponds to cloudy skies.\n",
    "            cl_sk_img = cv2.imread(cl_sk_imgpath, 0)\n",
    "            \n",
    "            # If there are more dark-colored pixels than light-colored pixels, then it's not cloudy.\n",
    "            if cv2.countNonZero(cv2.inRange(cl_sk_img, 0, 127)) > cv2.countNonZero(cv2.inRange(cl_sk_img, 128, 255)):\n",
    "                # clear skies\n",
    "                csv_row.append(\"clear\")\n",
    "            else:\n",
    "                # cloudy skies\n",
    "                csv_row.append(\"cloudy\")\n",
    "\n",
    "            # Finally, check if the image is mostly land or water.\n",
    "            lw_imgpath = os.path.join(land_water_map_path, lw_filelist[i])\n",
    "            if lw_imgpath in lw_results.keys():\n",
    "                csv_row.append(lw_results[lw_imgpath])\n",
    "            else:\n",
    "                lw_img = cv2.imread(lw_imgpath, 0)\n",
    "                # If there are more light-colored pixels than dark-colored pixels, then its mostly water\n",
    "                if cv2.countNonZero(cv2.inRange(lw_img, 128, 128)) > cv2.countNonZero(cv2.inRange(lw_img, 75, 75)):\n",
    "                    lw_results[lw_imgpath] = \"water\"\n",
    "                else:\n",
    "                    lw_results[lw_imgpath] = \"land\"\n",
    "                csv_row.append(lw_results[lw_imgpath])\n",
    "            writer.writerow(csv_row)\n",
    "\n",
    "print(\"Labeling complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (non-graph)\n",
    "Now that our data is labeled, we can start by training a baseline non-graph convolutional neural network classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms, models\n",
    "import random\n",
    "import ast\n",
    "\n",
    "# convert from strings to int representation of the labels\n",
    "def encode(label):\n",
    "    if label in ['clear', 'water']:\n",
    "        return 0\n",
    "    else: # cloudy, land\n",
    "        return 1\n",
    "\n",
    "# Used for obtaining the training/testing data\n",
    "def load_data(filename):\n",
    "    imgs = []\n",
    "    weather = []\n",
    "    terrain = []\n",
    "    with open(filename) as datacsv:\n",
    "        reader = csv.DictReader(datacsv)\n",
    "        for row in reader:\n",
    "            imgs.append(row[\"filepath\"])\n",
    "            weather.append(row[\"weather\"])\n",
    "            terrain.append(row[\"terrain\"])\n",
    "    shufflelist = list(zip(imgs, weather, terrain))\n",
    "    random.shuffle(shufflelist)\n",
    "    imgs, weather, terrain = zip(*shufflelist)\n",
    "    imgs, weather, terrain = list(imgs), list(weather), list(terrain)\n",
    "    # split into training and test data (use 3/4 for training, 1/4 for testing)\n",
    "    split_size = int(0.75 * len(imgs))\n",
    "    training_data = (imgs[:split_size], weather[:split_size], terrain[:split_size])\n",
    "    testing_data = (imgs[split_size:], weather[split_size:], terrain[split_size:])\n",
    "    return training_data, testing_data\n",
    "\n",
    "class CorrectedReflectanceDataset(tr.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.imgs, self.weather, self.terrain = data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # take the data sample by its index\n",
    "        img = Image.open(self.imgs[idx])\n",
    "\n",
    "        # Normalize the image and convert to tensor\n",
    "        transform1 = transforms.Compose([transforms.ToTensor()])\n",
    "        img_tr = transform1(img)\n",
    "        mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
    "        transform2 = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "        img = transform2(img)\n",
    "    \n",
    "        # return the image and the associated labels\n",
    "        dict_data = {\n",
    "            'img': img,\n",
    "            'labels': {\n",
    "                'weather_labels': self.weather[idx],\n",
    "                'terrain_labels': self.terrain[idx],\n",
    "            }\n",
    "        }\n",
    "        return dict_data\n",
    "    \n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, n_weather_classes, n_terrain_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = models.mobilenet_v2().features  # take the model without classifier\n",
    "        last_channel = models.mobilenet_v2().last_channel # size of the layer before the classifier\n",
    " \n",
    "        # the input for the classifier should be two-dimensional, but we will have\n",
    "        # [<batch_size>, <channels>, <width>, <height>]\n",
    "        # so, let's do the spatial averaging: reduce <width> and <height> to 1\n",
    "        self.pool = nn.AdaptiveAvgPool2D((1, 1))\n",
    " \n",
    "        # create separate classifiers for our outputs\n",
    "        self.weather = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=last_channel, out_features=n_weather_classes)\n",
    "        )\n",
    "        self.terrain = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=last_channel, out_features=n_terrain_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.pool(x)\n",
    "    \n",
    "        # reshape from [batch, channels, 1, 1] to [batch, channels] to put it into classifier\n",
    "        x = tr.flatten(x, start_dim=1)\n",
    "    \n",
    "        return {\n",
    "            'weather': self.weather(x),\n",
    "            'terrain': self.terrain(x)\n",
    "        }\n",
    "\n",
    "    def get_loss(self, net_output, ground_truth):\n",
    "        weather_loss = F.cross_entropy(net_output['weather'], ground_truth['weather_labels'])\n",
    "        terrain_loss = F.cross_entropy(net_output['terrain'], ground_truth['terrain_labels'])\n",
    "        loss = weather_loss + terrain_loss\n",
    "        return loss, {'weather': weather_loss, 'terrain': terrain_loss}\n",
    "\n",
    "filename = \"labeled_data.csv\"\n",
    "training_data, testing_data = load_data(filename)\n",
    "\n",
    "N_epochs = 50\n",
    "batch_size = 16\n",
    "device = 'cuda:0'\n",
    " \n",
    "model = MultiOutputModel(n_weather_classes=2, n_terrain_classes=2).to(device)\n",
    " \n",
    "optimizer = tr.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    epoch_start = time.time()\n",
    "    print(\"Epoch: {}/{}\".format(epoch+1, N_epochs))\n",
    "    # Set to training mode\n",
    "    model.train()\n",
    "    # Loss and Accuracy within the epoch\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        # Clean existing gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img = batch['img']\n",
    "        target_labels = batch['labels']\n",
    "        \n",
    "        # Forward pass - compute outputs on input data using the model\n",
    "        output = model(img.to(device))\n",
    "\n",
    "        # Compute loss\n",
    "        loss_train, losses_train = model.get_loss(output, target_labels)\n",
    "        total_loss += loss_train.item()\n",
    "        batch_accuracy_color, batch_accuracy_gender, batch_accuracy_article = calculate_metrics(output, target_labels)\n",
    "\n",
    "        # Backpropagate the gradients\n",
    "        loss_train.backward()\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute the total loss for the batch and add it to train_loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        # Compute the accuracy\n",
    "        ret, predictions = tr.max(outputs.data, 1)\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "        # Convert correct_counts to float and then compute the mean\n",
    "        acc = tr.mean(correct_counts.type(tr.FloatTensor))\n",
    "        # Compute total accuracy in the whole batch and add to train_acc\n",
    "        train_acc += acc.item() * inputs.size(0)\n",
    "        print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc2b5acaa58da8cb98f2f1f9c5a12e7ec9d328c197ca9485c680430a79d86e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
